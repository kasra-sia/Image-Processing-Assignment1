{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXcVIKgMygpb"
   },
   "source": [
    "\n",
    "<br>\n",
    "<font face=\"Times New Roman\">\n",
    "<div dir=ltr align=center>\n",
    "<font color=0F5298 size=7>\n",
    "Digital Image Processing <br>\n",
    "<font color=2565AE size=5>\n",
    "Department Of Mathematical Sciences <br>\n",
    "Spring 2025<br>\n",
    "<font color=3C99D size=5>\n",
    "Assignment 1 <br>\n",
    "</div>\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xW-igWTPA_s_"
   },
   "source": [
    "### Full Name : Kasra Siavashpour\n",
    "### Student Number :99109903\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWjdNUnCDBjn"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQWUbdJhDGkA"
   },
   "source": [
    "In this assignment, we are going to investigate some of the basic methods of image enhancement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ruZd34syvXJ"
   },
   "source": [
    "## Section 1: Image Enhancement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9S7rTpCeRxyP"
   },
   "source": [
    "Importing necessary Libraries. You cannot import and use any other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yxOOqePDRxCX"
   },
   "outputs": [],
   "source": [
    "# Do not modify this cell\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHY1SVKdz56I"
   },
   "source": [
    "### Q1: Intensity Enhancement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gkPm2i1AU7Y9"
   },
   "source": [
    "\n",
    "In this question, you will implement some of the intensity processing functions and apply them on a given image. In the final part, you will be asked to use these functions to enhance the intensity of a given image.\n",
    "x\n",
    "<ol>\n",
    "<li>\n",
    " <b>Negative Transform :</b> $y=255-x$\n",
    "\n",
    " <li>\n",
    " <b>Log Transform :</b> $y=\\frac{255 \\log(1+ \\alpha x)}{\\log(1+255 \\alpha)}$\n",
    "\n",
    " <li>\n",
    " <b>Gamma Transform :</b> $y=255(\\frac{x}{255})^{\\gamma}$\n",
    "\n",
    " </ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfL63V2kKmAz"
   },
   "source": [
    "In the following cells, complete the functions for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aoJXFg9RU-ft"
   },
   "outputs": [],
   "source": [
    "def negative_transform(img: np.ndarray):\n",
    "    # Negative transform: y = 255 - x\n",
    "    return 255 - img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9xN8kEf5Lere"
   },
   "outputs": [],
   "source": [
    "def log_transform(img: np.ndarray, alpha):\n",
    "    # Convert image to float for accurate computation\n",
    "    img_float = img.astype(np.float32)\n",
    "    # Log transform: y = 255 * log(1 + alpha*x) / log(1 + 255*alpha)\n",
    "    transformed = 255 * (np.log(1 + alpha * img_float) / np.log(1 + 255 * alpha))\n",
    "    # Clip values to [0, 255] and convert back to uint8\n",
    "    return np.uint8(np.clip(transformed, 0, 255))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JhdZKClKLpqN"
   },
   "outputs": [],
   "source": [
    "def gamma_transform(img: np.ndarray, gamma):\n",
    "    # Convert image to float for accurate computation\n",
    "    img_float = img.astype(np.float32)\n",
    "    # Gamma transform: y = 255 * (x/255)^gamma\n",
    "    transformed = 255 * ((img_float / 255) ** gamma)\n",
    "    # Clip values to [0, 255] and convert back to uint8\n",
    "    return np.uint8(np.clip(transformed, 0, 255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4kjbfAeL1My"
   },
   "source": [
    "Now, apply these transformations on `Q1-input1.jpg` (on RGB channels) and save the output images in `Q1-output-neg.jpg`, `Q1-output-log.jpg` and `Q1-output-gamma.jpg`, respectively. You can set $\\alpha$ and $\\gamma$ whatever you want, but effect on the intensity of the image should be noticable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7EhvIa-uMXt7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the first input image\n",
    "img1 = cv2.imread('input-images/Q1-input1.jpg')\n",
    "\n",
    "# Apply the transformations on each channel (functions work element-wise)\n",
    "img1_neg = negative_transform(img1)\n",
    "img1_log = log_transform(img1, alpha=0.05)   # alpha chosen to make the log effect visible\n",
    "img1_gamma = gamma_transform(img1, gamma=0.5)  # gamma < 1 brightens the image\n",
    "\n",
    "# Save the output images\n",
    "cv2.imwrite('output-images/Q1-output-neg.jpg', img1_neg)\n",
    "cv2.imwrite('output-images/Q1-output-log.jpg', img1_log)\n",
    "cv2.imwrite('output-images/Q1-output-gamma.jpg', img1_gamma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmKNF6lgNHPy"
   },
   "source": [
    "Finally, use the functions you implemented to enhance the intensity of `Q1-input2.jpg`. You may use any of the functions in anyway you desire. Your final score on the question depends on the quality of the output. Save the output image as `Q1-output-enhanced.jpg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YzZW06EXNqzu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2 = cv2.imread('input-images/Q1-input2.jpg')\n",
    "\n",
    "# Enhance the intensity of the second image by combining transformations.\n",
    "# Here, we first apply a gamma transform (with gamma=0.7 to brighten the image) \n",
    "# and then a log transform (with alpha=0.05) to boost details in darker regions.\n",
    "img2_enhanced = log_transform(gamma_transform(img2, gamma=0.7), alpha=0.05)\n",
    "\n",
    "# Save the enhanced image\n",
    "cv2.imwrite('output-images/Q1-output-enhanced.jpg', img2_enhanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rhQ9CuB0EBX"
   },
   "source": [
    "### Q2: Histogram Specification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDHfzOZEVFor"
   },
   "source": [
    "In this question, we will implement histogram specification for intensity enhancement.\n",
    "\n",
    "Complete the following code to specify the histogram of the input image, with a given histogram `hist1`, to target histogram `hist2`.\n",
    "\n",
    "**Note**: Assume that the input image has only one channel, i.e, it is a $H \\times W$ numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MvfW2Si2VPwe"
   },
   "outputs": [],
   "source": [
    "def histogram_specification(img: np.ndarray, hist1: np.ndarray, hist2: np.ndarray):\n",
    "    # Compute the cumulative distribution function (CDF) for both histograms\n",
    "    cdf1 = np.cumsum(hist1)\n",
    "    cdf2 = np.cumsum(hist2)\n",
    "    \n",
    "    # Normalize the CDFs to be in the range [0,1]\n",
    "    cdf1_normalized = cdf1 / cdf1[-1]\n",
    "    cdf2_normalized = cdf2 / cdf2[-1]\n",
    "    \n",
    "    # Build the lookup table (mapping) from source intensities to target intensities.\n",
    "    # For each intensity value i in the source, find the intensity j in the target\n",
    "    # such that the difference between cdf1[i] and cdf2[j] is minimized.\n",
    "    mapping = np.zeros(256, dtype=np.uint8)\n",
    "    for i in range(256):\n",
    "        # Find the target intensity that minimizes the absolute difference\n",
    "        diff = np.abs(cdf1_normalized[i] - cdf2_normalized)\n",
    "        mapping[i] = np.argmin(diff)\n",
    "    \n",
    "    # Apply the mapping to the image.\n",
    "    # Since img contains intensity values in [0,255], we can use the mapping as a LUT.\n",
    "    return mapping[img]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZLeTgXDb4RD"
   },
   "source": [
    "To test the above code, open `Q2-input1.jpg` and `Q2-input2.jpg`, and convert the histogram of the first one to the second one. Save the resulting image as `Q2-output.jpg`. The aim of specifying the histograms is to enhance the first image, so your score depends on the quality of your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "x7eoFt8Wck1k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = cv2.imread('input-images/Q2-input1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('input-images/Q2-input2.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Compute histograms for both images.\n",
    "# hist1: histogram of the source image; hist2: histogram of the target image.\n",
    "hist1 = cv2.calcHist([img1], [0], None, [256], [0, 256]).flatten()\n",
    "hist2 = cv2.calcHist([img2], [0], None, [256], [0, 256]).flatten()\n",
    "\n",
    "# Apply histogram specification: adjust the histogram of img1 to match that of img2.\n",
    "output_img = histogram_specification(img1, hist1, hist2)\n",
    "\n",
    "# Save the resulting image\n",
    "cv2.imwrite('output-images/Q2-output.jpg', output_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32u4wbZ5_kPh"
   },
   "source": [
    "### Q3: Color Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvwLbve8BFMw"
   },
   "source": [
    "In image `Q3-input.jpg`, change the color of the flowers red, blue and yellow to violet, pink and orange respectively. Save the result as `Q3-output.jpg`. Your score of this question depends on the quality of the output image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "8MpboAXMBuAZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img = cv2.imread('input-images/Q3-input.jpg')\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define HSV ranges for red (split into two parts)\n",
    "lower_red1 = np.array([0, 70, 50])\n",
    "upper_red1 = np.array([10, 255, 255])\n",
    "lower_red2 = np.array([170, 70, 50])\n",
    "upper_red2 = np.array([180, 255, 255])\n",
    "mask_red1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "mask_red2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "mask_red = cv2.bitwise_or(mask_red1, mask_red2)\n",
    "\n",
    "# Optionally refine the mask using morphological operations\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "mask_red = cv2.morphologyEx(mask_red, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "# --- Contour filtering for the red mask ---\n",
    "# Find contours in the red mask\n",
    "contours, _ = cv2.findContours(mask_red.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create an empty refined mask\n",
    "refined_mask_red = np.zeros_like(mask_red)\n",
    "\n",
    "# Filter contours by area (adjust the threshold as needed)\n",
    "for cnt in contours:\n",
    "    if cv2.contourArea(cnt) > 100:  # only keep regions with significant area\n",
    "        cv2.drawContours(refined_mask_red, [cnt], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "# Replace red regions with the target color (violet) using the refined mask\n",
    "output = img.copy()\n",
    "violet = (238, 130, 238)  # BGR for violet\n",
    "output[refined_mask_red > 0] = violet\n",
    "\n",
    "# You would similarly refine masks for blue and yellow,\n",
    "# then replace them with pink and orange respectively.\n",
    "\n",
    "# For demonstration, here's a similar approach for blue:\n",
    "lower_blue = np.array([90, 50, 50])\n",
    "upper_blue = np.array([130, 255, 255])\n",
    "mask_blue = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "mask_blue = cv2.morphologyEx(mask_blue, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "contours, _ = cv2.findContours(mask_blue.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "refined_mask_blue = np.zeros_like(mask_blue)\n",
    "for cnt in contours:\n",
    "    if cv2.contourArea(cnt) > 100:\n",
    "        cv2.drawContours(refined_mask_blue, [cnt], -1, 255, thickness=cv2.FILLED)\n",
    "pink = (193, 182, 255)  # BGR for pink\n",
    "output[refined_mask_blue > 0] = pink\n",
    "\n",
    "# And for yellow:\n",
    "lower_yellow = np.array([20, 70, 50])\n",
    "upper_yellow = np.array([35, 255, 255])\n",
    "mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "mask_yellow = cv2.morphologyEx(mask_yellow, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "contours, _ = cv2.findContours(mask_yellow.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "refined_mask_yellow = np.zeros_like(mask_yellow)\n",
    "for cnt in contours:\n",
    "    if cv2.contourArea(cnt) > 100:\n",
    "        cv2.drawContours(refined_mask_yellow, [cnt], -1, 255, thickness=cv2.FILLED)\n",
    "orange = (0, 165, 255)  # BGR for orange\n",
    "output[refined_mask_yellow > 0] = orange\n",
    "\n",
    "# Save the result\n",
    "cv2.imwrite('output-images/Q3-output.jpg', output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Oz6SF_vy1jE"
   },
   "source": [
    "## Section 2: Spatial Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMl0p0LT1Fh_"
   },
   "source": [
    "### Q4: Blurring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mKifczzVTE5"
   },
   "source": [
    "In this question, you are going to implement a function to blur a given image using a specified method. Your function should support box filter, gaussian filter and median filter. It is permitted to use `opencv` to perform the bluring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f468uatAVYfV"
   },
   "outputs": [],
   "source": [
    "def blur(img: np.ndarray, kernel_size: int, filter: string):\n",
    "  # TODO: implement blurring for box filter, Gaussian Blurring and median blurring\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUoRV0hICl34"
   },
   "source": [
    "Test your code with kernel size $k=3, 11, 25$ for each of filters on `Q4-input.jpg`. Save the output images with the following format:\n",
    "<ul>\n",
    "<li> Box filter with kernel size $k=3, 11, 25$ as Q4-output-box3.jpg, Q4-output-box11.jpg and Q4-output-box25.jpg.\n",
    "\n",
    "<li> Gaussian filter with kernel size $k=3, 11, 25$ as Q4-output-gauss3.jpg, Q4-output-gauss11.jpg and Q4-output-gauss25.jpg (you can set $\\sigma$ whaever you wish, but blurring should be observable).\n",
    "\n",
    "<li> Median filter with kernel size $k=3, 11, 25$ as Q4-output-med3.jpg, Q4-output-med11.jpg and Q4-output-med25.jpg.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wW4JyhVSEWsQ"
   },
   "outputs": [],
   "source": [
    "img=cv2.imread('Q4-input.jpg')\n",
    "# TODO: Apply the filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wtp-C2Jc1I-2"
   },
   "source": [
    "### Q5: Sharpening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dg6ZrsNTVcpr"
   },
   "source": [
    "In this question, you are going to sharpen a given image using Gaussian Filter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pS86V7JGGqeA"
   },
   "source": [
    "Let $f$ be the source image and $g$ be the Gaussian kernel, then $f*g$ is the convolution of the image with this kernel, which results in a blurred image.\n",
    "\n",
    "To sharpen the image, we can generate an unsharp mask by subtracting the blurred image from the original image:\n",
    "$$m=f-f*g$$\n",
    "This mask is a transparent image which has higher intensity on the edges of the original image. Now we may add this mask with a weight $\\alpha$ to sharpen the original image:\n",
    "$$f'=f+ \\alpha m$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVzOaQLluhs0"
   },
   "source": [
    "First, complete the following function to generate a Gaussian kernel with a given size and $\\sigma$. A $(2k+1) \\times (2k+1)$ Gaussian kernel has the value $e^{\\frac{-(x^2+y^2)}{2 \\sigma^2}}$ at point $(x,y)$ (Center of the kernel has coordinates $(0,0)$, and we have $x,y \\in [-k,k]$). You should also normalize the kernel (sum of the entries should app up to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g2MlbBACVlri"
   },
   "outputs": [],
   "source": [
    "def gaussian_kernel(kernel_size: int, sigma):\n",
    "  # TODO: create the gaussian kernel with given size and sigma\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NireMWeHvyq6"
   },
   "source": [
    "Next, complete the following function to sharpen a given image and Gaussian kernel and $\\alpha$. Your function should return both the sharpened image and the unsharp mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lF6-S0S-wHRp"
   },
   "outputs": [],
   "source": [
    "def gaussian_sharpen(img: np.ndarray, kernel: np.ndarray, alpha: float):\n",
    "  # TODO: sharpen the image and return both the result and unsharp mask\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sHM7o7Ufwn-I"
   },
   "source": [
    "Now to test your code, open `Q5-input.jpg` and sharpen it using the above function. Use a kernel size of 7 and choose a suitable value of $\\sigma$ and $\\alpha$ to get a desirable result. Save the sharpened image as `Q5-output-1.jpg` and the unsharp mask (grayscale image) as `Q5-output-2.jpg`. Your score on this part depends on the quality of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2m8sujORxXGg"
   },
   "outputs": [],
   "source": [
    "img=cv2.imread('Q5-input.jpg')\n",
    "# TODO: Sharpen the image and save the result and the unsharp mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMkJ7dVkr4nu"
   },
   "source": [
    "### Q6: Noise removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2J51bUZrxkJ"
   },
   "source": [
    "## A) ACE Function\n",
    "Implement the ACE function using ready-made functions for histogram equalization and padding. Apply the function with different grid sizes on ACE.jpg image and report the output for each one. Also specify which output is the best.\n",
    "\n",
    "## B) CLAHE Function\n",
    "Implement the CLAHE function and apply it to CLAHE.jpg image. Also specify which output is the best. In this function, test different values for the clipping threshold and grid size, analyze the effect of each, and output the best result.\n",
    "\n",
    "## C) add_noise Function\n",
    "Complete the add_noise function to add Gaussian or Salt-and-Pepper noise to the image. Using existing library functions is not allowed. Read the noise.tif image in grayscale and add Gaussian and Salt-and-Pepper noise separately to the image and display the output.\n",
    "\n",
    "## D) denoise Function\n",
    "Save the image resulting from adding Salt-and-Pepper noise and denoise it using an appropriate filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMOtSI77rblo"
   },
   "outputs": [],
   "source": [
    "def ACE(image, gridSize):\n",
    "  '''\n",
    "  inputs:\n",
    "    image (ndarray): input image\n",
    "    gridSize (tuple): window size for calculating histogram equalization\n",
    "  output:\n",
    "    output (ndarray): improved image\n",
    "  '''\n",
    "\n",
    "  ###############################################\n",
    "  ############# YOUR CODE GOES HERE #############\n",
    "\n",
    "  output = ...\n",
    "\n",
    "  ###############################################\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "huKL88B-scaB"
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "######## PLOT INPUT AND OUTPUT IMAGES##########\n",
    "\n",
    "\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UsJo8Y9hsJad"
   },
   "outputs": [],
   "source": [
    "def CLAHE(image, gridSize, threshold):\n",
    "  '''\n",
    "  inputs:\n",
    "    image (ndarray): input image\n",
    "    gridSize (tuple): window size for calculating histogram equalization\n",
    "    threshold (int): threshold for contrast limiting\n",
    "  output:\n",
    "    output (ndarray): improved image\n",
    "  '''\n",
    "  ###############################################\n",
    "  ############# YOUR CODE GOES HERE #############\n",
    "\n",
    "  output = ...\n",
    "\n",
    "  ###############################################\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzB0ZtLPseSn"
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "######## PLOT INPUT AND OUTPUT IMAGES##########\n",
    "\n",
    "\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50Yu-AhQsLu0"
   },
   "outputs": [],
   "source": [
    "def add_noise(image, noise_type, args):\n",
    "\n",
    "  '''\n",
    "  inputs:\n",
    "    image (ndarray): This is the input image represented as a NumPy array.\n",
    "\n",
    "    noise_type (int): This parameter specifies which type of noise to add.\n",
    "    It can take the following values:\n",
    "    0: Gaussian Noise\n",
    "    1: Salt-and-Pepper Noise\n",
    "\n",
    "    args (list): A list of arguments that contains additional parameters needed for each noise mode.The required arguments are different depending on the noise_type.\n",
    "\n",
    "  output:\n",
    "    output_image (ndarray): noisy image.\n",
    "\n",
    "\n",
    "  1. Gaussian Noise (noise_type = 0):\n",
    "\n",
    "    Arguments (passed via args):\n",
    "    mean: The mean of the Gaussian distribution (center value of noise).\n",
    "    sigma: the standard deviation (sigma) of the Gaussian distribution.\n",
    "\n",
    "    How it works:\n",
    "    Generate Gaussian noise with this mean and sigma that has the same shape as the input image.\n",
    "    Add this noise to the original image to create the noisy image.\n",
    "\n",
    "  2. Salt-and-Pepper Noise (noise_type = 1):\n",
    "\n",
    "    Arguments (passed via args):\n",
    "    prob: The probability of a pixel being changed to Salt, Pepper, or staying unchanged.\n",
    "\n",
    "    How it works:\n",
    "    For each pixel in the image, generate a random number.\n",
    "    If the random number is less than prob, change the pixel value to Salt (255).\n",
    "    If the random number is greater than 1 - prob, change the pixel value to Pepper (0).\n",
    "    Otherwise, leave the pixel unchanged.\n",
    "\n",
    "  '''\n",
    "  ###############################################\n",
    "  ############# YOUR CODE GOES HERE #############\n",
    "\n",
    "  if noise_type == 0: # Gaussian Noise\n",
    "    ...\n",
    "\n",
    "  else: # Salt-and-Pepper Noise\n",
    "    ...\n",
    "\n",
    "  ###############################################\n",
    "  return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRWRB0hfse_n"
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "######## PLOT INPUT AND OUTPUT IMAGES##########\n",
    "\n",
    "\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lo1B_7KpsOZv"
   },
   "outputs": [],
   "source": [
    "def denoise(noisy_image):\n",
    "\n",
    "  '''\n",
    "  input:\n",
    "    noisy_image (ndarray): the noisy image\n",
    "\n",
    "  output:\n",
    "    output_image (ndarray): denoised image\n",
    "\n",
    "  '''\n",
    "  ###############################################\n",
    "  ############# YOUR CODE GOES HERE #############\n",
    "\n",
    "  output = ...\n",
    "\n",
    "  ###############################################\n",
    "  return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQ2gi_9NsgDO"
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "######## PLOT INPUT AND OUTPUT IMAGES##########\n",
    "\n",
    "\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSQfavfErxBZ"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
